# -*- coding: utf-8 -*-
"""Resumo Curso imersão de dados (Alura).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZoLXkQUrxI62Mx1zZcTAM46z66esUDRS

Resumo curso Imersão de dados Alura
"""

import pandas as pd # framework - data analysis and manipulation tool.

font = "https://github.com/alura-cursos/imersao-dados-2-2020/blob/master/MICRODADOS_ENEM_2019_SAMPLE_43278.csv?raw=true" # Database no tipo csv

data = pd.read_csv(font) # Leitura da database no formato csv
data.head() # head() mostra somente as 5 primeiras linhas.

data_frame = data["NU_NOTA_MT"] # Planilha com dados [] -> lista de COLUNA a serem extraidos.

data_frame

data[["NU_NOTA_MT", "NU_NOTA_LC"]] # LISTA DE COLUNAS NA LISTA DE DADOS

"""Funções aprendidas no curso"""

# .unique() -> index unicos das linhas em uma coluna.
# .value_counts() -> soma de todas as linhas unicas.
# .sort_index() -> organiza os index das linhas.
# .hist(bins, figsize) -> grafico de barras de dados/ bins = numeros de barras / figsize = (x, y) tamanho
# .query('') -> se x linha é entra nessa variavel. (if)
# .describe() -> Resume os dados.
# .quantile(%) -> numero do 1 - % melhor 
# .dropna() -> tira todas as linhas q possuem NaN.

""".Plot funcs"""

# .box(grid=True) -> grafico de sei la o nome/ grid são linhas no grafico que ajudam na leitura.
# .bar(title) -> grafico de barras/ title é titulo.
# .pie(labels, autopct='%1.1f%%') -> Grafico de pizza/ labels= () de nomes para cada index/ autopct coloca porcentagem em todos.
# .scatter(x=,y=,data=) -> grafico de bulinhas de interseção.

"""Seaborn e mathplot"""

import seaborn as sns
import matplotlib.pyplot as plt # ajuda na criação de graficos

# plt.figure(figsize = (10, 8))
# sns.plot.box(x = , y =, data = , order = , hue =) -> Faz comparativo entre vários resultados possiveis
#hue coloca outra barra de comparação, usando outro dado.
# plt.title("")
# plt.gca().legend((legenda_index)) -> Coloca uma legenda.
# plt.xlim((x, y))
# plt.ylim((x, y))

# data[[lista]].corr() -> correlação de 0 a 1.
# sns.heatmap(corr, annot = True) -> mapa de calor com as correlações.

"""Machine Learning"""

from sklearn.model_selection import train_test_split
x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, test_size = , random_state=SEED)
# Criador das variaveis para machine learning
# random_state para não randomizar sempre q declarar

from sklearn.svm import LinearSVR
modelo = LinearSVR(random_state=SEED)
modelo.fit(x_treino, y_treino) # treina a maquina
# Criador bom para grandes amostras, grande aleatoriedade.
# .predict(x_teste) -> previsão

from sklearn.dummy import DummyRegressor
modelo_d = DummyRegressor()
# Criador simples, não use para problemas reais.

from sklearn.metrics import mean_squared_error
# mean_squared_error(y_true, y_pred)
# Erro quadrado médio

from sklearn.tree import DecisionTreeRegressor
# Criador de decisão em arvore com aleatoriedade baixissima
# modelo_tree = DecisionTreeRegressor(max_depth = 3) -> max_depth são as subdivisões
# muitas subdivisões causa um overfit, ruim.

from sklearn.model_selection import cross_validate
# Avalie a(s) métrica(s) por validação cruzada e também registre os tempos de ajuste / pontuação.
cross_validate(modelo, x, y, scoring = "neg_mean_squared_error")

from sklearn.model_selection import KFold # cv = parts -> dentro do cross_validate
parts = KFold(n_splits = 10, shuffle=True) # Divisões